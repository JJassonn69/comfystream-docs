---
title: "Customize LoRas"
description: "Learn how to customize the LoRas in your Stream Diffusion workflow"
icon: "image"
---

The [ComfyUI StreamDiffusion](http://localhost:3000/technical/reference/available-nodes#streamdiffusion) custom node supports SD 1.5 models and LoRa checkpoints. LoRas are used to generate a variety of special effects in your workflow, such as color correction, sharpening, and more.


## Configure LoRa checkpoint using ComfyUI
ComfyUI will automatically generate a workflow json file from changes in the lightgraph ui editor. Follow these steps to customize the LoRa checkpoints in your Stream Diffusion workflow:

1. Launch ComfyUI with the StreamDiffusion node installed
2. Choose an example [Stream Diffusion workflow](https://github.com/pschroedl/ComfyUI-StreamDiffusion/tree/main/examples/LoRAs) file that uses LoRas
3. Open the workflow file in ComfyUI
4. Change the `lora_name` input in the workflow to reflect the name of a LoRa checkpoint file you want to use 
5. From ComfyUI, run the workflow to validate the change, save the workflow file when done: **File > Save**
<Note>
Be sure to download the LoRa checkpoint files to the correct directory on your local machine. ComfyUI will not automatically download the LoRa checkpoint files until the workflow is deployed to the Livepeer AI Network
</Note>
6. Export and download the new workflow json file from ComfyUI: **File > Export > API**

### Checkpoint files
- LoRa Checkpoint files for [ComfyUI StreamDiffusion](http://localhost:3000/technical/reference/available-nodes#streamdiffusion) are downloaded from their huggingface repo [pschroedl/comfystream_checkpoints](https://huggingface.co/pschroedl/comfystream_checkpoints/tree/main)
- Files are stored in `ComfyUI/models/checkpoints` by default

## Configure LoRa checkpoint in workflow manually

### Changing the LoRa checkpoint
The `lora_name` input will reflect the name of a LoRa file from [pschroedl/comfystream_loras](https://huggingface.co/pschroedl/comfystream_loras/tree/main). 
<Note>See [examples/LoRAs/lahmixMysterious_alienzkin_lora_API_FORMAT.json#L15C1-L21C4](https://github.com/pschroedl/ComfyUI-StreamDiffusion/blob/a1b6aeb6a1281d40cfbfa557cf0c1db2090bbd50/examples/LoRAs/lahmixMysterious_alienzkin_lora_API_FORMAT.json#L15C1-L21C4)</Note>
```json
  "178": {
    "inputs": {
      "lora_name": "ral-alienzkin-sd15.safetensors"
    },
    "class_type": "StreamDiffusionCheckpointLoader"
  },
```
Update the `lora_name` input to the name of the LoRa checkpoint you want to use. Be sure to download the LoRa checkpoint file as it will not be downloaded automatically until deployed to the Livepeer AI Network

### Changing the StreamDiffusion model
Normally you will not need to change the model when switching LoRas, however LoRas are only compatible with specific SD models. 
If you need to change the model, the `checkpoint` input defines the stable diffusion model (sd_turbo, sd1.5, or a fine-tuned variant) that will be loaded by the workflow.
```json
  "178": {
    "inputs": {
      "checkpoint": "lahmixMysterious_v20.safetensors"
    },
    "class_type": "StreamDiffusionCheckpointLoader"
  },
```

## Submit your LoRa Checkpoint to Livepeer

To request your LoRa checkpoint to be officially deployed on the Livepeer Network:
- Open a pull request to the hugging-face repository [https://huggingface.co/pschroedl/comfystream_loras](https://huggingface.co/pschroedl/comfystream_loras/tree/main)
- Open a Pipeline Request ticket with the [Livepeer AI Support Team](#TODO).   
