---
title: "Install ComfyStream"
description: "A quick start guide to running your first AI video workflow with ComfyStream."
icon: "download"
---

ComfyStream is available as a docker image at [livepeer/comfystream:stable](https://hub.docker.com/r/livepeer/comfystream/tags?name=stable). An NVIDIA GPU is required to run ComfyStream. 

Choose a platform to install ComfyStream:
<CardGroup cols={2}>
  <Card title="Local GPU" icon="square-1" href="#local-gpu">
    Run ComfyStream and ComfyUI on Linux or Windows with a local GPU
  </Card>
  <Card title="Remote GPU" icon="square-2" href="#remote-gpu">
    Deploy and run ComfyStream and ComfyUI on a any remote server with a rented GPU
  </Card>
</CardGroup>

<h2>Local GPU</h2>

### Prerequisites

First, install the required system software:
<AccordionGroup>
  <Accordion title="Linux">
    - [Docker Engine](https://docs.docker.com/engine/install/ubuntu/#install-using-the-repository)
    - [NVIDIA CUDA Toolkit](https://developer.nvidia.com/cuda-12-6-3-download-archive?target_os=Linux&target_arch=x86_64&Distribution=Ubuntu)
    - [NVIDIA Container Toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html)
  </Accordion>

  <Accordion title="Windows">
    <Steps>
      <Step title="Install WSL 2">
        - From a new command prompt, run: `wsl --install`
        - Update WSL if needed: `wsl.exe --update`
      </Step>
      
      <Step title="Launch Ubuntu in Terminal">
        Launch a new Terminal, then open a tab for **Ubuntu (WSL)**.
      </Step>
      
      <Step title="Install NVIDIA CUDA Toolkit">
        Inside of WSL, install [NVIDIA CUDA Toolkit](https://developer.nvidia.com/cuda-12-6-3-download-archive?target_os=Windows&target_arch=x86_64&target_version=11&target_type=exe_local) for WSL.
      </Step>
      
      <Step title="Install Docker Desktop">
        Install [Docker Desktop for Windows](https://docs.docker.com/get-started/introduction/get-docker-desktop/) for Windows.
      </Step>
      
      <Step title="Configure Docker Desktop">
        Ensure WSL 2 Engine is enabled in Docker Desktop settings.
      </Step>
      
      <Step title="Verify Docker access">
        Inside of WSL, run `docker ps` to verify you have access to docker.
      </Step>
      
      <Step title="Continue with setup">
        From the WSL Terminal, continue with the steps below to setup the local environment
      </Step>
    </Steps>
  </Accordion>
</AccordionGroup>

### Setting Up Local Environment 

<Steps>
  <Step title="Create directories for models and output">
    <CodeGroup>
    ```bash Linux
    mkdir -p ~/models/ComfyUI--models ~/models/ComfyUI--output  
    ```
    ```batch Command Line
    mkdir %USERPROFILE%\models\ComfyUI--models %USERPROFILE%\models\ComfyUI--output
    ```
    ```powershell PowerShell
    New-Item -ItemType Directory -Path "$env:USERPROFILE\models\ComfyUI--models", "$env:USERPROFILE\models\ComfyUI--output"
    ```
    </CodeGroup>
  </Step>
  
  <Step title="Pull the ComfyStream container">
    ```bash
    docker pull livepeer/comfystream:stable
    ```
    
    <Info>
    If using Windows, ensure Docker Desktop is running first
    </Info>
  </Step>
  
  <Step title="Run the container">
    <CodeGroup>
    ```bash Linux/WSL
    docker run -it --gpus all \
    -p 8188:8188 \
    -p 8889:8889 \
    -p 5678:5678 \
    -v ~/models/ComfyUI--models:/workspace/ComfyUI/models \
    -v ~/models/ComfyUI--output:/workspace/ComfyUI/output \
    livepeer/comfystream:stable --download-models --build-engines --server
    ```
    </CodeGroup>
    
    <Note>
    The `--download-models` and `--build-engines` flags will download required models and build TensorRT engines. This process may take some time depending on your network connection and GPU hardware and is only needed on the first run or when adding new models.
    </Note>
  </Step>
</Steps>

<h2 id="remote-gpu">Remote GPU</h2>

ComfyStream can be deployed on any cloud provider with GPU support. Documentation includes multiple options for remote deployment:

<AccordionGroup>
  <Accordion title="Deploy using Ansible Playbooks (Cloud-Agnostic)">
    Ansible Playbooks offer a repeatable, reusable deployment system for deploying ComfyStream on any cloud provider. The included playbook automates the entire setup process.

    ### Prerequisites

    1. **Create a VM**:  
       Deploy a VM on a cloud provider such as TensorDock, AWS, Google Cloud, or Azure with the following minimum specifications:
       - **GPU**: 20GB VRAM  
       - **RAM**: 16GB  
       - **CPU**: 4 vCPUs  
       - **Storage**: 100GB

    2. **Open Required Ports**:  
       Ensure the following ports are open **inbound and outbound** on the VM's firewall/security group:
       - **SSH (Port 22)** – Remote access  
       - **HTTPS (Port 8189)** – ComfyStream access  
      
    3. **Install Ansible (on your local machine only)**:  
       Ansible must be installed on your local machine (the control node). Follow the [official Ansible installation guide](https://docs.ansible.com/ansible/latest/installation_guide/index.html).

    ### Deployment Steps

    <Steps>
      <Step title="Download the Ansible Playbook and Inventory">
        Clone the ComfyStream repository to your local machine (where Ansible is installed):
        
        ```bash
        git clone https://github.com/livepeer/comfystream.git
        cd comfystream/scripts/ansible
        ```
        
        This will give you access to both the playbook and the inventory file needed for deployment.
        
        <Info>
        You do NOT need to install Ansible on the cloud server. Ansible runs from your local machine and connects to the server over SSH.
        </Info>
      </Step>
      <Step title="Configure the Inventory File">
        Add the VM's public IP to the `inventory.yml` file.
      </Step>
      
      <Step title="Change the ComfyUI Password">  
        Open the `plays/setup_comfystream.yaml` file and replace the `comfyui_password` value with your own secure password.
      </Step>
      
      <Step title="Run the Playbook from Your Local Machine">  
        Navigate to the ansible directory and execute this command from your local machine (where you cloned the repository):

        ```bash
        ansible-playbook -i inventory.yaml plays/setup_comfystream.yaml
        ```

        <Info>
        When using a non-sudo user, add `--ask-become-pass` to provide the sudo password.
        </Info>
      </Step>
        <Accordion title="Checking Docker Image Download Progress">
    The ComfyStream Docker image is approximately 20GB. To check download progress, SSH into the VM and run:
    ```bash
    docker pull livepeer/comfystream:latest
    ```
  </Accordion>
      <Step title="Access the Server">  
        After the playbook completes, **ComfyStream** will start, and you can access **ComfyUI** at `https://<VM_IP>:<PORT_FOR_8189>`. 

        To persist the password, set the `comfyui_password` variable when running the playbook:

        ```bash
        ansible-playbook -i inventory.yaml plays/setup_comfystream.yaml -e "comfyui_password=YourSecurePasswordHere"
        ```
      </Step>
    </Steps>


  </Accordion>

  <Accordion title="Deploy on TensorDock (Fully Automated)">
    TensorDock provides affordable GPU instances perfect for running ComfyStream. We offer a fully automated script that handles VM provisioning, setup, and server launch.

    ### Prerequisites

    1. **Create a TensorDock Account**: 
       Sign up at [Tensordock](https://dashboard.tensordock.com/signup), add a payment method, and generate API credentials.

    2. **Clone the ComfyStream Repository**:
       The deployment script is part of the ComfyStream repository. Clone it to your local machine:
       ```bash
       git clone https://github.com/livepeer/comfystream.git
       cd comfystream/scripts
       ```

    3. **Set Up a Python Environment**:
       Create and activate a virtual environment with [Conda](https://docs.anaconda.com/miniconda/) and install the required dependencies from the `requirements.txt`
        <Warning>
       You need to have Conda installed on your local machine. If you don't have Conda installed, you can download and install it from [here](https://www.anaconda.com/docs/getting-started/miniconda/install).
       </Warning>

       ```bash
       conda create -n comfystream python=3.8
       conda activate comfystream
       pip install -r requirements.txt
       ```

    ### Deployment Steps

    <Steps>
      <Step title="Run the Script">  
        You must provide either a password OR an SSH key for VM access (not both):

        **Using a password:**
        ```bash
        python spinup_comfystream_tensordock.py --api-key <API_KEY> --api-token <API_TOKEN> --password <SECURE_PASSWORD>
        ```

        **Using an SSH key:**
        ```bash
        python spinup_comfystream_tensordock.py --api-key <API_KEY> --api-token <API_TOKEN> --public-ssh-key "$(cat ~/.ssh/id_rsa.pub)"
        ```
        
        <Info>
        The script will automatically generate a separate strong password for accessing the ComfyUI web interface.
        </Info>

        **Useful optional flags:**
        - `--vm-name <NAME>`: Custom name for your VM
        - `--max-price <PRICE>`: Maximum hourly price (default: 0.5 USD)
        - `--location "City, Country"`: Preferred location for the VM
        - `--qr-code`: Generate QR code for easy access
      </Step>
      
      <Step title="Wait for Setup and Access Information">  
        The setup process can take up to 30 minutes. Once complete, the script will display:
        - ComfyUI URL `https://<VM_IP>:<PORT>`
        - ComfyUI username: `comfyadmin`
        - Auto-generated ComfyUI password
        - SSH command to access the VM
        
        <Note>
        Make sure to save the auto-generated ComfyUI password securely!
        </Note>
      </Step>
      
      <Step title="Stop & Delete the VM (When No Longer Needed)">
        To avoid unnecessary charges, delete the VM when you're done:

        ```bash
        python spinup_comfystream_tensordock.py --api-key <API_KEY> --api-token <API_TOKEN> --delete <VM_ID>
        ```

        Replace `<VM_ID>` with the VM ID found in the script logs or the `TensorDock dashboard`
      </Step>
    </Steps>
  </Accordion>

  <Accordion title="Deploy on RunPod">
    <Steps>
      <Step title="Deploy using the RunPod template">
        Use the template [livepeer-comfystream](https://runpod.io/console/deploy?template=w01m180vxx&ref=u8tlskew)
        <Note>
        First-time deployment to a network volume takes approximately 20-45 minutes depending on pod performance. 
        For faster deployment without data persistence, use the RunPod template [livepeer-comfystream-novolume](https://runpod.io/console/deploy?template=j4p1g7t5vs&ref=u8tlskew)
        </Note>
      </Step>
      
      <Step title="Create a network volume">
        When using the [livepeer-comfystream](https://runpod.io/console/deploy?template=w01m180vxx&ref=u8tlskew) template, create and select a network volume to persist files.
        ![New Network Volume](../../images/networkvolume.png)
      </Step>
      
      <Step title="Select GPU and deploy">
        Select an appropriate GPU (ex: RTX 4090) and click **Deploy On-Demand**
      </Step>
      
      <Step title="Monitor deployment progress">
        Click the **Logs** button to monitor deployment progress.
        ![runpod-log](../../images/runpod-log.png)
      </Step>
      
      <Step title="Access ComfyUI">
        Once the container is fully running, you can access ComfyUI by clicking **Connect**
      </Step>
    </Steps>
  </Accordion>
</AccordionGroup>


## Accessing ComfyUI
<AccordionGroup>
  <Accordion title="Remote">
  1. Click **Connect** in pod dashboard
    ![comfyui-connect-pod](../../images/comfyui-connect-pod.png)
  2. Access ComfyUI: **HTTP Service -> :8188**
  3. ComfyUI will open in a new tab
  </Accordion>

  <Accordion title="Local">
  When running the docker image locally, you can access ComfyUI at [http://localhost:8188](http://localhost:8188).
  </Accordion>
</AccordionGroup>

## Accessing ComfyStream 
1. From ComfyUI, click the **ComfyStream** menu button:
![comfystream-node-ui.png](../../images/comfystream-node-ui.png)

2. Click **Server Settings** to verify ComfyStream is configured to bind to the correct interface and port <Note>When deploying to remote environments like RunPod, you will need to set the Host to `0.0.0.0`. </Note>
![comfystream-server-settings.png](../../images/comfystream-server-settings.png)
3. Click **Save**.
4. Open the **ComfyStream** menu again, then click **Start ComfyStream Server**. Wait for the server status indicator to turn green. 
    <Note>
    You can monitor ComfyStream server logs in ComfyUI's log terminal tab.
    </Note>
5. Click **Open ComfyStream UI** to launch in a new tab.
Alternatively, you can double-click the node graph and search for **ComfyStream UI Preview**
![comfystream-ui-embed.png](../../images/comfystream-ui-embed.png)

---

## Troubleshooting

<AccordionGroup>
  <Accordion title="Docker Hub Rate Limits (toomanyrequests error)">
    <Note>
    If you encounter a `toomanyrequests` error while pulling the Docker image, either wait a few minutes or provide your Docker credentials when running the playbook:
    
    ```bash
    ansible-playbook -i inventory.yaml plays/setup_comfystream.yaml -e "docker_hub_username=your_dockerhub_username docker_hub_password=your_dockerhub_pat"
    ```
    </Note>
  </Accordion>
  <Accordion title="TensorDock Deployment Issues">
    <Note>
    If you encounter `max retries exceeded with URL` errors during TensorDock deployment, the VM might have been created but is inaccessible. Check the [TensorDock dashboard](https://dashboard.tensordock.com/instances), delete the VM manually, wait 2-3 minutes, then rerun the script.
    </Note>
  </Accordion>
</AccordionGroup>
